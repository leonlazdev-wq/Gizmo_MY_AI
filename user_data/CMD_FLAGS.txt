--listen --share --verbose --api --api-port 5000 --auto-launch --loader llama.cpp --gpu-layers -1 --ctx-size 4096 --batch-size 512 --threads 4
